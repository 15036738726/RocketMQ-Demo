官网:
https://rocketmq.apache.org/zh/docs/4.x/


前提配置JDK
JAVA_HOME=/opt/jdk1.7.0_79
PATH=$JAVA_HOME/bin:$PATH
CLASSPATH=$JAVA_HOME/lib:.
export JAVA_HOME PATH CLASSPATH


启动命令:
bin
nohup sh mqnamesrv > ../logs/namesrv.log &
nohup sh mqbroker c ../conf/broker.conf > ../logs/borker.log &


nohup java -jar rocketmq-dashboard-1.0.0.jar --server.port=8001 > dashboard.log &


https://www.cnblogs.com/holly8/p/17779198.html
修改静态指定IP
编辑ens33网卡的配置信息
vi /etc/sysconfig/network-scripts/ifcfg-ens33
将BOOTPROTO="dhcp"自动获取修改为static
文件末尾追加 固定IP  如  IPADDR=192.168.100.128


Linux命令：
查看防火墙状态：systemctl  status firewalld
关闭防火墙：systemctl stop firewalld


Linux没有ens33解决方案
解决ens33丢失问题
systemctl stop NetworkManager                             临时关闭
systemctl disable NetworkManager                          永久关闭网络管理命令
systemctl start network.service                           开启网络服务




下面是整理的面试题

===========================================================
如何保证消息按照顺序消费
1.发送者方需要把消息按照顺序放入同一个队列  2.消费者采用顺序消费的方式(说是单线程模式不太合理,官方说法是顺序消费模式,即一个队列由一个线程去消费;并发消费模式默认20个线程消费4个队列保证不了有序性)
(发送顺序消息,或者发送批量消息,都可以让消息放入同一个队列里边)


重复消费问题解决方案[面试重要]
引起原因:
1.重复投递 
2.消费者方扩容时引起重复消费(增加来消费者,队列进行了Rebalance重平衡分配,1一个消费者4个队列[0,1,2,3] 2个消费者时各管理2个队列)
(取出消息消费跟消费成功后位点向后移动是两个动作,如果在消费过程中,突然增加了一个消费者,
此时A消息正在消费,位点还没有移动之前,增加的消费者分到了该消息所在队列,发现位点指针指向A消息,则消费)


如下场景:生产者发送订单消息  消费方的业务逻辑是对应减少对应商品的库存操作  如果重复消费则商品的库存数据是不正确的
解决思路,在消费端进行去重处理:
通过redis或者mysql记录消息唯一ID(被消费了的消息需要记录一下,因为这两个容器都有持久化机制,千万不能存内存,分布式项目,多台机器内存不共享)
Mysql的新增操作是原子的  如果存在唯一性约束,即使并发插入 最终也只能插入一条成功,后续的都失败
1.新建一个去重表(官方叫法),设置业务字段唯一性约束(比如订单号)
2.每次对消息进行消费的时候,首先取出唯一性业务字段,(执行业务字段订单号的插入操作),如果插入成功,则执行后续的业务代码(减库存),
如果插入失败(违反唯一性约束),说明之前这个消息已经来过了,则不做任何业务操作(消息签收掉即可)

	 * 我们设计一个去重表 对消息的唯一key添加唯一索引
	 * 每次消费消息的时候 先插入数据库 如果成功则执行业务逻辑 [如果业务逻辑执行报错 则删除这个去重表记录,说明业务逻辑有bug,消息消费失败了,ConsumeConcurrentlyStatus.RECONSUME_LATER; 稍后重试消费消息]
	 * 如果插入失败 则说明消息来过了,直接签收了 ConsumeConcurrentlyStatus.CONSUME_SUCCESS;


下面是官网的原话:
消费过程幂等
RocketMQ无法避免消息重复（Exactly-Once），所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理。可以借助关系数据库进行去重。
首先需要确定消息的唯一键，可以是msgId，也可以是消息内容中的唯一标识字段，例如订单Id等。在消费之前判断唯一键是否在关系数据库中存在。
如果不存在则插入，并消费，否则跳过。（实际过程要考虑原子性问题，判断是否存在可以尝试插入，如果报主键冲突，则插入失败，直接跳过）
msgId一定是全局唯一标识符，但是实际使用中，可能会存在相同的消息有两个不同msgId的情况（消费者主动重发、因客户端重投机制导致的重复等），这种情况就需要使业务字段进行重复消费

-------------------------------------

消息重试,工作中死信消息解决方案:
当消费重试到达阈值以后，消息不会被投递给消费者了，而是进入了死信队列
当一条消息初次消费失败，RocketMQ会自动进行消息重试，达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息。
此时，该消息不会立刻被丢弃，而是将其发送到该消费者对应的特殊队列中，这类消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue），
死信队列是死信Topic下分区数唯一的单独队列。如果产生了死信消息，那对应的ConsumerGroup的死信Topic名称为%DLQ%ConsumerGroupName，死信队列的消息将不会再被消费。
可以利用RocketMQ Admin工具或者RocketMQ Dashboard上查询到对应死信消息的信息。我们也可以去监听死信队列，然后进行自己的业务上的逻辑

默认重试次数为16次,默认从第三个时间间隔级别开始重试  都可修改
10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h
如果重试了16次(并发模式) 顺序模式下(int最大值次)都是失败的?  是一个死信消息 则会放在一个死信主题中去,这个主题中只有一个队列
主题的名称 %DLQ%+消费组名称
当消息处理失败的时候 该如何正确的处理?  都是通过人工进行消费处理,发送邮件等等.... 下面是两种解决思路:
第一种解决方案 直接监听死信主题的消息,记录下来 通知人工接入处理
但是,第一种方案 每个消费者组都要创建一个对应的死信监听方法  如果有几十个组的话 也太繁琐了
第二种方案 用法比较多:
我们在消息监听的流程控制中 就直接可以进行重试次数的判断  如果达到设定的阈值  可以直接人工处理,然后消息签收了,不让其做无畏的重试了
consumer.registerMessageListener(new MessageListenerConcurrently() {
	@Override
	public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
		MessageExt messageExt = msgs.get(0);
		System.out.println(new Date());
		try {
			// 业务处理
			handleDb();
		} catch (Exception e) {
			// 业务报错了 进行重试
			// 获取重试次数
			int reconsumeTimes = messageExt.getReconsumeTimes();
			// 重试3次 因为发送时设置来重试次数为2 第一次消费不算重试次数  消费一次 次数+1  0(第一次) 1 2 
			if (reconsumeTimes >= 2) {
				// 不要重试了
				System.out.println("记录到特别的位置 文件 mysql 通知人工处理");
				return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
			}
			// 没有达到阈值,则重试
			return ConsumeConcurrentlyStatus.RECONSUME_LATER;
		}
		// 业务没有报错,并且执行完毕,签收消息
		return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
	}
});

-------------------------------------
如何解决消息堆积问题?[面试重要]

产生原因:
第一种情况.生产太快了,生产消息的速度远远大于处理消息的速度
第二种情况.消费者消费出现问题
第一种情况:
生产方可以做业务限流;
增加消费者数量,但是消费者数量<=队列数量;
动态扩容队列数量,默认4个队列,从而增加消费者数量;
根据消费方处理的任务类型,适当的设置消费者线程数量,默认是20,(IO密集型(2n),CPU密集型(n+1)) IO:磁盘操作较多,大量的sql交互   CUP:计算多  n是当前机器的最大线程数,动态获取Runtime.getRuntime().availableProcessors() 不要写死;
官网原话:
同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。
提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadNumber实现。

如果是第二种情况:
排查消费者程序的问题(程序报错,导致消息签收失败,频繁重试消费);
程序自身存在bug,执行时间过长,比如,存在慢sql交互;


-------------------------------------
如何确保消息不丢失?[面试重要]
产生原因:异步刷盘机制;	一共两种机制,同步刷盘/异步刷盘机制(mq内部持久化机制)

发送同步消息流程:消息由生产者发送到 borker,然后进行同步刷盘成功之后(mq内部的存储机制,采用的是顺序读写,速度也不慢) 然后发送结果给生产者,这种发送一般消息时不会丢失的,除非磁盘坏了
他的思想就是borker接受到消息,并且对消息执行刷盘持久化之后,才返回发送成功给生产者
而发送异步消息,则是把消息先放入缓冲区(内存,然后通知生产者数据发送成功),待一定时机才进行刷盘动作,而且mq模式的刷盘机制就是异步刷盘,一旦宕机,这些内存中缓冲的消息就会有丢失的风险,下次重启就找不到了 
解决办法如下几种:
第一种.生产者使用同步发送模式(性能不太好,一般都是用异步)
第二种.将mq的刷盘机制设置为同步刷盘(不推荐) 

第三种推荐:那么如果采用异步发送方式该如何处理呢?
思想,自己记录消息(不在依赖于mq的持久化,自己记录)
发送方异步发送,在发送方收到发送成功通知的时候,在异步回调方法内部执行一个数据持久化动作
insert 消息业务ID,状态=1(标识未消费),创建时间
消费者方,处理完业务逻辑之后,更新这个消息的状态为0(标识已经消费)
update  状态=0,消费时间
然后每间隔一段时间去查询表中的这些记录(通过定时任务),那些消息是发了很久的,但是没有被消费的,那么这些消息是不是就是丢失了?
然后发送者方,通过表中的数据可以进行消息补发即可,消费者方只要保证好幂等性原则(不要重复消费,因为消息可能在mq中排队,还没有来得消费呢),就可以了
如上被补发的消息大概由以下两种原因:
1.P端生产者,异步发送的消息,在缓冲区的消息在刷盘之前丢失
2.C端消费者,没有及时消费的消息(所以C端一定要控制好幂等性操作)


mq底层设计(源码文档中写的)
1.1 消息存储整体架构
消息主要是顺序写入日志文件CommitLog中(一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度)
然后通过异步分发的方式放入消息消费队列ConsumeQueue中
引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。
Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，
消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件,
同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，
可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M
1.3 消息刷盘
(1) 同步刷盘：如上图所示，只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。
(2) 异步刷盘：能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量

===========================================================
并发:多个任务在同一个时间段内执行
并行:在多核CPU上,多个任务在同一时刻执行

QPS:每秒钟处理请求的数量  tomcat 1s 500

https://baijiahao.baidu.com/s?id=1767578085827593075&wfr=spider&for=pc
QPS（TPS）= 并发数/平均响应时间





